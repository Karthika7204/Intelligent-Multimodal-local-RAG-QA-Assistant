# Intelligent Multimodal Local RAG â€“ QA Assistant

A **local Multimodal Retrieval-Augmented Generation (RAG) system** that enables **Question Answering over PDFs, Images, and Audio files** using a Streamlit-based UI. This project runs fully **offline/local**, leveraging vector search (FAISS) and LLM-based reasoning to provide context-aware answers from user-uploaded documents.

---

## Project Webpages

## ğŸš€ Features

* ğŸ“„ **PDF Question Answering** â€“ Ask questions from resumes, policies, reports, and other documents
* ğŸ–¼ï¸ **Image-based Q&A** â€“ Extract and reason over text content from images
* ğŸ”Š **Audio-based Q&A** â€“ Ask questions from uploaded audio files (speech-to-text supported)
* ğŸ§  **Multimodal RAG Pipeline** â€“ Combines retrieval + generation for accurate responses
* ğŸ” **FAISS Vector Index** â€“ Efficient similarity search over embedded content
* ğŸ§© **Local Execution** â€“ No cloud dependency; runs entirely on your machine
* ğŸŒ **Streamlit UI** â€“ Clean and interactive web interface

---

## ğŸ—ï¸ Project Architecture

```
User Query
   â†“
Document Upload (PDF / Image / Audio)
   â†“
Text Extraction (OCR / STT / PDF Parsing)
   â†“
Text Chunking
   â†“
Embedding Generation
   â†“
FAISS Vector Store (Local)
   â†“
Relevant Context Retrieval
   â†“
LLM Response Generation
```

---

## ğŸ“‚ Project Structure

```
Intelligent-Multimodal-local-RAG-QA-Assistant/
â”‚
â”œâ”€â”€ data/                 # Uploaded and processed documents
â”œâ”€â”€ faiss_index/          # Stored FAISS vector indexes
â”œâ”€â”€ sapp.py               # Main Streamlit application
â”œâ”€â”€ requirements.txt      # Project dependencies
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ§‘â€ğŸ’» Tech Stack

* **Python 3.9+**
* **Streamlit** â€“ UI framework
* **FAISS** â€“ Vector similarity search
* **LangChain / LLM utilities** (as applicable)
* **OCR / Speech-to-Text** â€“ For image & audio processing
* **OpenAI / Local LLMs** (configurable)

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/<your-username>/Intelligent-Multimodal-local-RAG-QA-Assistant.git
cd Intelligent-Multimodal-local-RAG-QA-Assistant
```

### 2ï¸âƒ£ Create Virtual Environment (Recommended)

```bash
python -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Running the Application

```bash
streamlit run sapp.py
```

The app will be available at:

```
http://localhost:8501
```

---

## ğŸ§ª Example Use Case

* Upload **MyResume.pdf** and **policy.pdf**
* Ask: *"Who is the candidate in the resume and are they eligible for the policy?"*
* The system:

  * Extracts content from both documents
  * Retrieves relevant sections
  * Provides a grounded, context-aware answer

---

## ğŸ” Privacy & Security

* All files are processed **locally**
* No document data is stored externally
* Ideal for **sensitive documents** such as resumes, medical policies, and internal reports

---

## ğŸ“Œ Limitations

* Eligibility or medical fitness cannot be inferred unless explicitly stated in documents
* OCR accuracy depends on image quality
* Audio clarity impacts transcription quality

---

## ğŸ› ï¸ Future Enhancements

* âœ… Support for video-based Q&A
* âœ… Advanced document-level citations
* âœ… Multi-language support
* âœ… UI-based index management
* âœ… Integration with fully local LLMs (LLaMA, Mistral, etc.)

---

## ğŸ‘©â€ğŸ’» Author

**Karthika B**
AI & Computer Vision Enthusiast

---

## â­ Acknowledgements

* FAISS by Meta AI
* Streamlit Community
* Open-source LLM ecosystem

---

## ğŸ“œ License

This project is open-source and available under the **MIT License**.

---

If you find this project useful, donâ€™t forget to â­ the repository!
